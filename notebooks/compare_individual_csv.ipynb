{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    'Aof',\n",
    "    'Beam',\n",
    "    'Eye',\n",
    "    'Faai',\n",
    "    'Fluke',\n",
    "    'Fong',\n",
    "    'Joke',\n",
    "    'Pod',\n",
    "    'Tau',\n",
    "    'Toey',\n",
    "    'Tong',\n",
    "    'Torn'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [\n",
    "    'Aof-t20 (1024Hz)',\n",
    "    'Aof-t21 (1024Hz)',\n",
    "    'Aof-t22 (1024Hz)',\n",
    "    'Aof-t23 (1024Hz)',\n",
    "    'Aof-t24 (1024Hz)',\n",
    "    'Aof-t25 (1024Hz)',\n",
    "    'Beam-t1 (1024Hz)',\n",
    "    'Beam-t2 (1024Hz)',\n",
    "    'Beam-t3 (1024Hz)',\n",
    "    'Beam-t6 (1024Hz)',\n",
    "    'Beam-t7 (1024Hz)',\n",
    "    'Beam-t8 (1024Hz)',\n",
    "#     'Donut-t1 (1024Hz)',\n",
    "#     'Donut-t2 (1024Hz)',\n",
    "#     'Donut-t3 (1024Hz)',\n",
    "#     'Donut-t4 (1024Hz)',\n",
    "#     'Donut-t5 (1024Hz)',\n",
    "#     'Donut-t6 (1024Hz)',\n",
    "#     'Donut-t7 (1024Hz)',\n",
    "#     'Eye-t1 (1024Hz)',\n",
    "    'Eye-t2 (1024Hz)',\n",
    "    'Eye-t3 (1024Hz)',\n",
    "    'Eye-t4 (1024Hz)',\n",
    "    'Eye-t5 (1024Hz)',\n",
    "    'Eye-t6 (1024Hz)',\n",
    "    'Eye-t7 (1024Hz)',\n",
    "    'Faai-t1 (1024Hz)',\n",
    "    'Faai-t2 (1024Hz)',\n",
    "    'Faai-t3 (1024Hz)',\n",
    "    'Faai-t4 (1024Hz)',\n",
    "    'Faai-t5 (1024Hz)',\n",
    "    'Faai-t6 (1024Hz)',\n",
    "    'Fluke-t20 (1024Hz)',\n",
    "    'Fluke-t21 (1024Hz)',\n",
    "    'Fluke-t22 (1024Hz)',\n",
    "    'Fluke-t23 (1024Hz)',\n",
    "    'Fluke-t24 (1024Hz)',\n",
    "    'Fluke-t25 (1024Hz)',\n",
    "    'Fong-t1 (1024Hz)',\n",
    "    'Fong-t2 (1024Hz)',\n",
    "    'Fong-t3 (1024Hz)',\n",
    "    'Fong-t4 (1024Hz)',\n",
    "    'Fong-t5 (1024Hz)',\n",
    "    'Fong-t6 (1024Hz)',\n",
    "    'Fong-t7 (1024Hz)',\n",
    "    'Fong-t8 (1024Hz)',\n",
    "    'Joke-t1 (1024Hz)',\n",
    "    'Joke-t2 (1024Hz)',\n",
    "    'Joke-t3 (1024Hz)',\n",
    "    'Joke-t4 (1024Hz)',\n",
    "    'Joke-t5 (1024Hz)',\n",
    "    'Joke-t6 (1024Hz)',\n",
    "    'Pod-t20 (1024Hz)',\n",
    "    'Pod-t21 (1024Hz)',\n",
    "    'Pod-t22 (1024Hz)',\n",
    "    'Pod-t23 (1024Hz)',\n",
    "    'Pod-t24 (1024Hz)',\n",
    "    'Pod-t25 (1024Hz)',\n",
    "    'Pod-t26 (1024Hz)',\n",
    "    'Tau-t11 (1024Hz)',\n",
    "    'Tau-t13 (1024Hz)',\n",
    "    'Tau-t14 (1024Hz)',\n",
    "    'Tau-t15 (1024Hz)',\n",
    "    'Tau-t16 (1024Hz)',\n",
    "    'Tau-t17 (1024Hz)',\n",
    "    'Tau-t18 (1024Hz)',\n",
    "    'Toey-t1 (1024Hz)',\n",
    "    'Toey-t2 (1024Hz)',\n",
    "    'Toey-t3 (1024Hz)',\n",
    "    'Toey-t4 (1024Hz)',\n",
    "    'Toey-t5 (1024Hz)',\n",
    "    'Toey-t6 (1024Hz)',\n",
    "    'Toey-t7 (1024Hz)',\n",
    "    'Tong-t1 (1024Hz)',\n",
    "    'Tong-t2 (1024Hz)',\n",
    "    'Tong-t3 (1024Hz)',\n",
    "    'Tong-t4 (1024Hz)',\n",
    "    'Tong-t5 (1024Hz)',\n",
    "    'Tong-t6 (1024Hz)',\n",
    "#     'Torn-t1 (1024Hz)',\n",
    "#     'Torn-t2 (1024Hz)',\n",
    "#     'Torn-t3 (1024Hz)',\n",
    "    'Torn-t4 (1024Hz)',\n",
    "    'Torn-t5 (1024Hz)',\n",
    "    'Torn-t6 (1024Hz)',\n",
    "    'Torn-t7 (1024Hz)',\n",
    "    'Torn-t8 (1024Hz)',\n",
    "    'Torn-t9 (1024Hz)'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_dir = './data/label/1/'\n",
    "second_dir = './data/label/2/'\n",
    "out_dir = './data/stat/individual/'\n",
    "\n",
    "infiles_1 = [first_dir + s + '.json' for s in filenames]\n",
    "infiles_2 = [second_dir + s + '_LABEL.json' for s in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_single_segment(label_data_1, label_data_2):\n",
    "    i = 0\n",
    "    j = 0\n",
    "    remove_index_1 = []\n",
    "    remove_index_2 = []\n",
    "    \n",
    "    while i < label_data_1.shape[0] and j < label_data_2.shape[0]:\n",
    "        if label_data_2[j][0] > label_data_1[i][0] - 2048 and label_data_2[j][0] < label_data_1[i][0] + 2048:\n",
    "            i += 1\n",
    "            j += 1\n",
    "        else:\n",
    "            if label_data_1[i][0] < label_data_2[j][0]:\n",
    "                # remove i\n",
    "                remove_index_1.append(i)\n",
    "                i += 1\n",
    "            else:\n",
    "                # remove j\n",
    "                remove_index_2.append(j)\n",
    "                j += 1\n",
    "    while i < label_data_1.shape[0]:\n",
    "        remove_index_1.append(i)\n",
    "        i += 1\n",
    "    while j < label_data_2.shape[0]:\n",
    "        remove_index_2.append(j)\n",
    "        j += 1\n",
    "    \n",
    "    mask_1 = np.ones(label_data_1.shape[0], dtype = bool)\n",
    "    mask_1[remove_index_1] = False\n",
    "    \n",
    "    mask_2 = np.ones(label_data_2.shape[0], dtype = bool)\n",
    "    mask_2[remove_index_2] = False\n",
    "\n",
    "    return label_data_1[mask_1], label_data_2[mask_2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Aof\n",
      "185\n",
      "Processing Beam\n",
      "189\n",
      "Processing Eye\n",
      "181\n",
      "Processing Faai\n",
      "210\n",
      "Processing Fluke\n",
      "188\n",
      "Processing Fong\n",
      "241\n",
      "Processing Joke\n",
      "178\n",
      "Processing Pod\n",
      "210\n",
      "Processing Tau\n",
      "246\n",
      "Processing Toey\n",
      "212\n",
      "Processing Tong\n",
      "194\n",
      "Processing Torn\n",
      "184\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "with open('./data/stat_csv/width_by_individual_aof.csv', 'w', newline='') as fout_1, open('./data/stat_csv/width_by_individual_tong.csv', 'w', newline='') as fout_2, open('./data/stat_csv/starting_point_diff_by_individual.csv', 'w', newline='') as fout_3, open('./data/stat_csv/ending_point_diff_by_individual.csv', 'w', newline='') as fout_4:\n",
    "    fieldnames = ['Name', 'N', 'Mean', 'Med', 'Std', 'Min', 'Max']\n",
    "    writer_1 = csv.DictWriter(fout_1, fieldnames = fieldnames)\n",
    "    writer_1.writeheader()\n",
    "    \n",
    "    writer_2 = csv.DictWriter(fout_2, fieldnames = fieldnames)\n",
    "    writer_2.writeheader()\n",
    "    \n",
    "    writer_3 = csv.DictWriter(fout_3, fieldnames = fieldnames)\n",
    "    writer_3.writeheader()\n",
    "    \n",
    "    writer_4 = csv.DictWriter(fout_4, fieldnames = fieldnames)\n",
    "    writer_4.writeheader()\n",
    "    for i in range(0, len(names)):\n",
    "        print(\"Processing \" + names[i])\n",
    "        np_label_data_1 = np.empty(shape=[0, 2])\n",
    "        np_label_data_2 = np.empty(shape=[0, 2])\n",
    "        for j in range(0, len(filenames)):\n",
    "            name, _ = filenames[j].split('-')\n",
    "            if name == names[i]:\n",
    "                label_data_1_tmp = json.load(open(infiles_1[j]))\n",
    "                label_data_2_tmp = json.load(open(infiles_2[j]))\n",
    "                \n",
    "                np_label_data_1_tmp = np.array(label_data_1_tmp)\n",
    "                np_label_data_2_tmp = np.array(label_data_2_tmp)\n",
    "\n",
    "                np_label_data_1_tmp, np_label_data_2_tmp = remove_single_segment(np_label_data_1_tmp, np_label_data_2_tmp)\n",
    "                \n",
    "                if len(np_label_data_1_tmp) == len(np_label_data_2_tmp):\n",
    "                    np_label_data_1 = np.concatenate((np_label_data_1, np_label_data_1_tmp), axis = 0)\n",
    "                    np_label_data_2 = np.concatenate((np_label_data_2, np_label_data_2_tmp), axis = 0)\n",
    "                else:\n",
    "                    print(\"{0}: Length not equal\".format(filenames[j]))\n",
    "\n",
    "        if len(np_label_data_1) != len(np_label_data_2):\n",
    "            print(\"{0}: Length not equal\".format(names[i]))\n",
    "            continue\n",
    "            \n",
    "        print(len(np_label_data_1))\n",
    "\n",
    "        # Extract starting and ending points\n",
    "        start_1 = np.array([d['start'] for d in np_label_data_1[:,1]])\n",
    "        start_2 = np.array([d['start'] for d in np_label_data_2[:,1]])\n",
    "        end_1 = np.array([d['end'] for d in np_label_data_1[:,1]])\n",
    "        end_2 = np.array([d['end'] for d in np_label_data_2[:,1]])\n",
    "\n",
    "        # Calculate width\n",
    "        width_1 = end_1 - start_1\n",
    "        width_2 = end_2 - start_2\n",
    "\n",
    "        # Calculate diff\n",
    "        start_diff = np.abs(start_1 - start_2)\n",
    "        end_diff = np.abs(end_1 - end_2)\n",
    "\n",
    "        stat = {}\n",
    "\n",
    "        stat['1'] = {}\n",
    "        stat['1']['mean'] = np.mean(width_1)\n",
    "        stat['1']['med'] = np.median(width_1)\n",
    "        stat['1']['min'] = np.min(width_1)\n",
    "        stat['1']['max'] = np.max(width_1)\n",
    "        stat['1']['std'] = np.std(width_1)\n",
    "\n",
    "        writer_1.writerow({'Name': names[i],\n",
    "                           'N': len(np_label_data_1),\n",
    "                           'Mean': '{:.6f}'.format(stat['1']['mean']),\n",
    "                           'Med': '{:.6f}'.format(stat['1']['med']),\n",
    "                           'Std': '{:.6f}'.format(stat['1']['std']),\n",
    "                           'Min': '{:.6f}'.format(stat['1']['min']),\n",
    "                           'Max': '{:.6f}'.format(stat['1']['max'])\n",
    "                          })\n",
    "\n",
    "        stat['2'] = {}\n",
    "        stat['2']['mean'] = np.mean(width_2)\n",
    "        stat['2']['med'] = np.median(width_2)\n",
    "        stat['2']['min'] = np.min(width_2)\n",
    "        stat['2']['max'] = np.max(width_2)\n",
    "        stat['2']['std'] = np.std(width_2)\n",
    "\n",
    "        writer_2.writerow({'Name': names[i],\n",
    "                           'N': len(np_label_data_1),\n",
    "                           'Mean': '{:.6f}'.format(stat['2']['mean']),\n",
    "                           'Med': '{:.6f}'.format(stat['2']['med']),\n",
    "                           'Std': '{:.6f}'.format(stat['2']['std']),\n",
    "                           'Min': '{:.6f}'.format(stat['2']['min']),\n",
    "                           'Max': '{:.6f}'.format(stat['2']['max'])\n",
    "                          })\n",
    "\n",
    "        stat['start_diff'] = {}\n",
    "        stat['start_diff']['mean'] = np.mean(start_diff)\n",
    "        stat['start_diff']['med'] = np.median(start_diff)\n",
    "        stat['start_diff']['min'] = np.min(start_diff)\n",
    "        stat['start_diff']['max'] = np.max(start_diff)\n",
    "        stat['start_diff']['std'] = np.std(start_diff)\n",
    "\n",
    "        writer_3.writerow({'Name': names[i],\n",
    "                           'N': len(np_label_data_1),\n",
    "                           'Mean': '{:.6f}'.format(stat['start_diff']['mean']),\n",
    "                           'Med': '{:.6f}'.format(stat['start_diff']['med']),\n",
    "                           'Std': '{:.6f}'.format(stat['start_diff']['std']),\n",
    "                           'Min': '{:.6f}'.format(stat['start_diff']['min']),\n",
    "                           'Max': '{:.6f}'.format(stat['start_diff']['max'])\n",
    "                          })\n",
    "\n",
    "        stat['end_diff'] = {}\n",
    "        stat['end_diff']['mean'] = np.mean(end_diff)\n",
    "        stat['end_diff']['med'] = np.median(end_diff)\n",
    "        stat['end_diff']['min'] = np.min(end_diff)\n",
    "        stat['end_diff']['max'] = np.max(end_diff)\n",
    "        stat['end_diff']['std'] = np.std(end_diff)\n",
    "\n",
    "        writer_4.writerow({'Name': names[i],\n",
    "                           'N': len(np_label_data_1),\n",
    "                           'Mean': '{:.6f}'.format(stat['end_diff']['mean']),\n",
    "                           'Med': '{:.6f}'.format(stat['end_diff']['med']),\n",
    "                           'Std': '{:.6f}'.format(stat['end_diff']['std']),\n",
    "                           'Min': '{:.6f}'.format(stat['end_diff']['min']),\n",
    "                           'Max': '{:.6f}'.format(stat['end_diff']['max'])\n",
    "                          })\n",
    "\n",
    "    fout_1.close()\n",
    "    fout_2.close()\n",
    "    fout_3.close()\n",
    "    fout_4.close()\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
